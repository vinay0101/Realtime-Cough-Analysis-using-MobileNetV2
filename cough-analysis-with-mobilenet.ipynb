{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nimport time\n\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\ndata_generator = ImageDataGenerator(rescale=1./255.,validation_split=0.2,\n                                   featurewise_center=True,\n        samplewise_center=True,\n        featurewise_std_normalization=True,\n        samplewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.15,\n        fill_mode=\"nearest\",\n        horizontal_flip=True,\n        vertical_flip=True\n                        )\ntrain_generator = data_generator.flow_from_directory(directory= '../input/cough-detection/melspectrograms/training',             \n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='training',\n                                                     shuffle=True,\n                                                     seed=2,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                     )\n\nvalid_generator = data_generator.flow_from_directory(directory= '../input/cough-detection/melspectrograms/testing',\n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='validation',\n                                                     shuffle=True,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                    )\n\nclasses = ['cough', 'no_cough']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.bar(classes, train_generator.labels.sum(axis = 0)/train_generator.n * 100)\nplt.title('On training set')\nplt.subplot(2,2,2)\nplt.bar(classes, valid_generator.labels.sum(axis = 0)/valid_generator.n * 100, color='rgb')\nplt.title('On validation set')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_training_images, _ = next(train_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    labels = sample_training_images\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotImages(sample_training_images[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3), classes=2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.layers[0].trainable = False\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2)\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=15,\n                              validation_steps = len(valid_generator),\n                              validation_data=valid_generator,\n                              callbacks = [callbacks]\n                              )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"preds = model.predict_generator(valid_generator,steps=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = valid_generator.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred= model.predict(valid_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (valid_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/cough-detection/melspectrograms/testing/cough/1-63679-A-24.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/cough-detection/melspectrograms/testing/no_cough/1-100032-A-0.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions1 = model.predict(input_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting Non Cough samples","metadata":{}},{"cell_type":"code","source":"image_path = '../input/cough-detection/melspectrograms/training/no_cough/1-100038-A-14.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions_nocough = model.predict(input_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nocough","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n\nrc = roc_curve(predicted_class_indices,label)\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_report = classification_report(predicted_class_indices,label)\nprint('Confusion matrix report of the model : \\n{}'.format(cf_matrix))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Classification report of the model : \\n{}'.format(cf_report))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"t = time.time()\nsave_path = '.'\nmodel_json = model.to_json()\nwith open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n    json_file.write(model_json)\n\n# save neural network structure to YAML (no weights)\nmodel_yaml = model.to_yaml()\nwith open(os.path.join(save_path,\"network.yaml\"), \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n\n# save entire network to HDF5 (save everything, suggested)\nmodel.save(os.path.join(save_path,\"network.h5\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Saved Model and Predictions","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel2 = load_model(os.path.join(save_path,\"network.h5\"))\npred = model2.predict(input_arr)\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}